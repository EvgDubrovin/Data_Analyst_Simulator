{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26f66b6b-d3ef-42d7-b942-7a2cafe4c5c1",
   "metadata": {},
   "source": [
    "# Построение ETL-пайплайна"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c939a6-262e-41aa-9bee-9ccbfd992ede",
   "metadata": {},
   "source": [
    "Ожидается, что на выходе будет DAG в airflow, который будет считаться каждый день за вчера. \n",
    "\n",
    "1. Параллельно будем обрабатывать две таблицы. В feed_actions для каждого юзера посчитаем число просмотров и лайков контента. В message_actions для каждого юзера считаем, сколько он получает и отсылает сообщений, скольким людям он пишет, сколько людей пишут ему. Каждая выгрузка должна быть в отдельном таске.\n",
    "2. Далее объединяем две таблицы в одну.\n",
    "3. Для этой таблицы считаем все эти метрики в разрезе по полу, возрасту и ос. Делаем три разных таска на каждый срез.\n",
    "4. И финальную данные со всеми метриками записываем в отдельную таблицу в ClickHouse.\n",
    "\n",
    "Структура финальной таблицы должна быть такая:\n",
    "* Дата - event_date\n",
    "* Пол - gender\n",
    "* Возраст - age\n",
    "* Операционная система - os\n",
    "* Число просмотров - views\n",
    "* Числой лайков - likes\n",
    "* Число полученных сообщений - messages_received\n",
    "* Число отправленных сообщений - messages_sent\n",
    "* От скольких пользователей получили сообщения - users_received\n",
    "* Скольким пользователям отправили сообщение - users_sent\n",
    "\n",
    "Вашу таблицу необходимо загрузить в схему test, ответ на это задание - название Вашей таблицы в схеме test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24626e0-5387-4a61-b16d-35d70a401bc9",
   "metadata": {},
   "source": [
    "## 1. Запросы к таблицам feed_actions и message_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f13ab5a-33ff-4e85-b6a6-1b8d0725c928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем необходимые библиотеки\n",
    "import pandas as pd\n",
    "import pandahouse\n",
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator \n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "\n",
    "from airflow.decorators import dag, task\n",
    "from airflow.operators.python import get_current_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "273921af-7e6d-4d29-bbf7-5e2300b49e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задаем параметры в DAG\n",
    "default_args = {\n",
    "    'owner': 'evg.dubrovin',             # Владелец операции\n",
    "    'depends_on_past': False,            # Зависимость от прошлых запусков\n",
    "    'retries': 2,                        # Кол-во попыток выполнить DAG\n",
    "    'retry_delay': timedelta(minutes=5), # Промежуток между перезапусками\n",
    "    'start_date': datetime(2022, 5, 17)  # Дата начала выполнения DAG\n",
    "}\n",
    "# Интервал запуска DAG\n",
    "schedule_interval = '0 10 * * *'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1376c99a-a33d-41cf-9c59-41a9de1c215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подключаемся к БД\n",
    "def ch_get_df(query):\n",
    "    connection_1 = {\n",
    "                   'host': 'https://clickhouse.lab.karpov.courses',\n",
    "                   'password': 'dpo_python_2020',\n",
    "                   'user': 'student',\n",
    "                   'database': 'simulator_20220420'\n",
    "                    }\n",
    "    result = pandahouse.read_clickhouse(query, connection=connection_1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6baadbe3-5a43-4934-86cf-dbd7c2967688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DAG\n",
    "@dag(default_args=default_args, schedule_interval=schedule_interval, catchup=False)\n",
    "def dag_dubrovin():\n",
    "    \n",
    "    @task\n",
    "    # В feed_actions для каждого юзера посчитаем число просмотров и лайков контента\n",
    "    def extract_feed():\n",
    "        query = '''\n",
    "            SELECT\n",
    "                user_id,\n",
    "                toDate(time) as event_date,\n",
    "                MIN(gender) as gender,\n",
    "                MIN(age) as age,\n",
    "                MIN(os) as os, \n",
    "                countIf(action='view') as views, \n",
    "                countIf(action='like') as likes\n",
    "            FROM\n",
    "                simulator_20220420.feed_actions\n",
    "            WHERE\n",
    "                toDate(time) = yesterday()\n",
    "            GROUP BY\n",
    "                user_id, event_date\n",
    "            '''\n",
    "        feed_df = ch_get_df(query=query)\n",
    "        return feed_df\n",
    "    \n",
    "    @task\n",
    "    # В message_actions для каждого юзера считаем, сколько он получает и отсылает сообщений, скольким людям он пишет, сколько людей пишут ему\n",
    "    def extract_messenger():\n",
    "        # \n",
    "        query_1 = '''\n",
    "            SELECT \n",
    "                CASE\n",
    "                    WHEN reciever_id = 0 THEN user_id\n",
    "                    WHEN user_id = 0 THEN reciever_id\n",
    "                    ELSE user_id\n",
    "                END as user_id,\n",
    "                yesterday() as event_date,\n",
    "                messages_received,\n",
    "                messages_sent,\n",
    "                users_received,\n",
    "                users_sent\n",
    "            FROM\n",
    "                -- Для каждого юзера посчитаем, сколько он отсылает сообщений и скольким людям он пишет\n",
    "                (\n",
    "                SELECT\n",
    "                    user_id,\n",
    "                    toDate(time) as event_date,\n",
    "                    COUNT(reciever_id) as messages_sent,\n",
    "                    uniqExact(reciever_id) as users_sent\n",
    "                FROM\n",
    "                    simulator_20220420.message_actions\n",
    "                WHERE\n",
    "                    toDate(time) = yesterday()\n",
    "                GROUP BY\n",
    "                    user_id,\n",
    "                    event_date\n",
    "                ) sent\n",
    "\n",
    "                FULL JOIN\n",
    "\n",
    "                -- Для каждого юзера посчитаем, сколько он получает сообщений и сколько людей пишут ему\n",
    "                (\n",
    "                SELECT\n",
    "                    reciever_id,\n",
    "                    toDate(time) as event_date,\n",
    "                    COUNT(user_id) as messages_received,\n",
    "                    uniqExact(user_id) as users_received\n",
    "                FROM\n",
    "                    simulator_20220420.message_actions\n",
    "                WHERE\n",
    "                    toDate(time) = yesterday()\n",
    "                GROUP BY\n",
    "                    reciever_id,\n",
    "                    event_date\n",
    "                ) received\n",
    "\n",
    "                ON sent.user_id = received.reciever_id\n",
    "            '''\n",
    "        messenger_df_0 = ch_get_df(query=query_1)\n",
    "        \n",
    "        # Пол, возраст и ОС пользователей мессенджера\n",
    "        query_2 = '''\n",
    "            SELECT\n",
    "                id as user_id,\n",
    "                MIN(gender) as gender, \n",
    "                MIN(age) as age, \n",
    "                MIN(os) as os\n",
    "            FROM\n",
    "                (SELECT\n",
    "                    user_id as id,\n",
    "                    MIN(gender) as gender,\n",
    "                    MIN(age) as age,\n",
    "                    MIN(os) as os\n",
    "                FROM\n",
    "                    simulator_20220420.message_actions\n",
    "                WHERE\n",
    "                    toDate(time) = yesterday()\n",
    "                GROUP BY\n",
    "                    id\n",
    "\n",
    "                UNION ALL\n",
    "\n",
    "                SELECT\n",
    "                    reciever_id as id,\n",
    "                    MIN(gender) as gender,\n",
    "                    MIN(age) as age,\n",
    "                    MIN(os) as os\n",
    "                FROM\n",
    "                    simulator_20220420.message_actions\n",
    "                WHERE\n",
    "                    toDate(time) = yesterday()\n",
    "                GROUP BY\n",
    "                    id)\n",
    "            GROUP BY\n",
    "                user_id\n",
    "            '''\n",
    "        messenger_attributes_df = ch_get_df(query=query_2)\n",
    "        \n",
    "        # Объединение таблиц messenger\n",
    "        messenger_df = pd.merge(messenger_df_0, messenger_attributes_df, on='user_id', how='inner')\n",
    "        \n",
    "        return messenger_df\n",
    "    \n",
    "    \n",
    "    \n",
    "    @task\n",
    "    # Объединяем feed и messenger\n",
    "    def merge_tables(feed_df, messenger_df):\n",
    "        full_df = pd.merge(feed_df, messenger_df, on=['user_id', 'event_date', 'gender', 'age', 'os'], how='outer').fillna(0)\n",
    "        \n",
    "        # Предобработка full_df\n",
    "        # Заменим float значения на int\n",
    "        float_cols = ['views', 'likes', 'messages_received', 'messages_sent', 'users_received', 'users_sent']\n",
    "        full_df[float_cols] = full_df[float_cols].astype(int)\n",
    "\n",
    "        # Заменим значения 0 и 1 в столбце gender на более понятные male и female\n",
    "        full_df.loc[full_df['gender']==0, 'gender'] = 'male'\n",
    "        full_df.loc[full_df['gender']==1, 'gender'] = 'female'\n",
    "\n",
    "        # Разобъем значения age на bins для удобства \n",
    "        age_min = full_df['age'].min()\n",
    "        age_max = full_df['age'].max()\n",
    "\n",
    "        age_groups = [f'{age_min}-18', '19-25', '26-45', '46-65', '66+']\n",
    "        age_bins = [age_min, 18, 25, 45, 65, age_max]\n",
    "        full_df['age_bins'] = pd.cut(full_df['age'], bins=age_bins, labels=age_groups)\n",
    "        \n",
    "        return full_df\n",
    "\n",
    "    \n",
    "    \n",
    "    # Для общей таблицы считаем все эти метрики в разрезе по полу, возрасту и ос. Делаем три разных таска на каждый срез\n",
    "    @task\n",
    "    # Считаем метрики по полу\n",
    "    def metrics_by_gender(full_df):\n",
    "        metrics = ['gender','event_date','views','likes','messages_received','messages_sent','users_received','users_sent']\n",
    "        metrics_by_gender = full_df[metrics].groupby(['gender','event_date'], as_index=[True, False]).sum()\n",
    "        return metrics_by_gender\n",
    "    \n",
    "    @task\n",
    "    # Считаем метрики по возрасту\n",
    "    def metrics_by_age(full_df):\n",
    "        metrics = ['age_bins','event_date','views','likes','messages_received','messages_sent','users_received','users_sent']\n",
    "        metrics_by_age = full_df[metrics].groupby(['age_bins','event_date'], as_index=[True, False]).sum()\n",
    "        return metrics_by_age\n",
    "    \n",
    "    @task\n",
    "    # Считаем метрики по ОС\n",
    "    def metrics_by_os(full_df):\n",
    "        metrics = ['os','event_date','views','likes','messages_received','messages_sent','users_received','users_sent']\n",
    "        metrics_by_os = full_df[metrics].groupby(['os','event_date'], as_index=[True, False]).sum()\n",
    "        return metrics_by_os\n",
    "    \n",
    "    \n",
    "    # Финальные данные со всеми метриками записываем в отдельную таблицу в ClickHouse\n",
    "    @task\n",
    "    # Получаем необходимую таблицу\n",
    "    def get_fin_table(full_df):\n",
    "        fin_df = full_df[['event_date', 'gender', 'age_bins', 'os', 'views', 'likes', 'messages_received', 'messages_sent', 'users_received', 'users_sent']]\n",
    "        fin_df = fin_df.groupby(['event_date', 'gender', 'age_bins', 'os'], as_index=False).sum().rename({'age_bins':'age'}, axis=1)\n",
    "        return fin_df\n",
    "    \n",
    "    @task\n",
    "    # Загружаем финальную таблицу в схему test\n",
    "    def load_table(fin_df):\n",
    "        # Подключаемся к БД\n",
    "        connection_2 = {\n",
    "            'host': 'https://clickhouse.lab.karpov.courses',\n",
    "            'password': '656e2b0c9c',\n",
    "            'user': 'student-rw',\n",
    "            'database': 'test'\n",
    "        }\n",
    "        # Создаем таблицу\n",
    "        q = '''\n",
    "            CREATE TABLE IF NOT EXISTS test.evg_dubrovin \n",
    "                (\n",
    "                event_date datetime,\n",
    "                gender TEXT,\n",
    "                age TEXT, \n",
    "                os TEXT,\n",
    "                views INTEGER,\n",
    "                likes INTEGER,\n",
    "                messages_received INTEGER,\n",
    "                messages_sent INTEGER,\n",
    "                users_received INTEGER,\n",
    "                users_sent INTEGER\n",
    "                )\n",
    "                ENGINE = MergeTree \n",
    "                ORDER BY (event_date);\n",
    "            '''\n",
    "        # Отправляем таблицу в базу данных\n",
    "        pandahouse.execute(connection=connection_2, query=q)\n",
    "        pandahouse.to_clickhouse(df=fin_df, table='evgdubrovin_test', index=False, connection=connection_2)\n",
    "        \n",
    "    \n",
    "    \n",
    "    # Выполняем таски \n",
    "    # В feed_actions для каждого юзера посчитаем число просмотров и лайков контента. \n",
    "    feed_df = extract_feed()\n",
    "    # В message_actions для каждого юзера считаем, сколько он получает и отсылает сообщений, скольким людям он пишет, сколько людей пишут ему\n",
    "    messenger_df = extract_messenger()\n",
    "    \n",
    "    # Далее объединяем две таблицы в одну\n",
    "    full_df = merge_tables(feed_df, messenger_df)\n",
    "    \n",
    "    # Метрики в разрезе по полу\n",
    "    metrics_by_gender = metrics_by_gender(full_df)\n",
    "    # Метрики в разрезе по возрасту\n",
    "    metrics_by_age = metrics_by_age(full_df)\n",
    "    # Метрики в разрезе по ОС\n",
    "    metrics_by_os = metrics_by_os(full_df)\n",
    "    \n",
    "    # Финальная таблица со всеми данными\n",
    "    fin_df = get_fin_table(full_df)\n",
    "    \n",
    "    # Загружаем таблицу в базу данных\n",
    "    load_table(fin_df)\n",
    "    \n",
    "dag_dubrovin = dag_dubrovin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1958d631-8c4a-4411-917f-52ff21bd0d4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
